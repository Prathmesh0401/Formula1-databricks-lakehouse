{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dfc1aebe-99b1-463e-b19d-4af460d3efdb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"/?o=1046699569939209#setting/sparkui/1216-080236-r9lzzt0b/driver-6597697878895198200\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v4.0.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*, 4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Databricks Shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f357456b2c0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57a7cec3-2db7-455a-9b28-9fea46336d76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'4.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64c8fecf-e3ae-4f59-b9c9-ad06efdedb6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'spark.databricks.sql.optimizer.replaceAlias.maxExpressionNumNodes': '100000',\n",
       " 'spark.databricks.clusterUsageTags.isDpCpPrivateLinkEnabled': 'false',\n",
       " 'spark.hadoop.fs.abfs.impl.disable.cache': 'true',\n",
       " 'spark.databricks.cloudFiles.aws.restrictSNSPolicyPrincipalAndAccount': 'false',\n",
       " 'spark.databricks.variant.shreddingBeta.enabled': 'false',\n",
       " 'spark.hadoop.fs.azure.user.agent.prefix': '',\n",
       " 'spark.databricks.optimizer.decorrelateQueriesWithVariantFields.enabled': 'false',\n",
       " 'spark.hadoop.databricks.s3.create.deleteUnnecessaryFakeDirectories': 'false',\n",
       " 'spark.delta.sharing.client.useStructuralSchemaMatch': 'true',\n",
       " 'spark.databricks.scan.useRelativePathsDuringFileListing': 'true',\n",
       " 'spark.databricks.remoteQueryTVFEnabled': 'false',\n",
       " 'spark.hadoop.fs.local-file.impl': 'com.databricks.backend.daemon.driver.WorkspaceLocalFileSystem',\n",
       " 'spark.databricks.scheduler.executorConnectivityExclusion.enabled': 'false',\n",
       " 'spark.databricks.autotune.maintenance.enableMultipleColumnOrPredicateTracking': 'false',\n",
       " 'spark.databricks.clusterUsageTags.clusterNoDriverDaemon': 'false',\n",
       " 'spark.databricks.delta.multiClusterWrites.enabled': 'true',\n",
       " 'spark.hadoop.fs.fcfs-abfs.impl': 'com.databricks.sql.acl.fs.FixedCredentialsFileSystem',\n",
       " 'spark.databricks.clusterUsageTags.cloudProvider': 'Azure',\n",
       " 'spark.databricks.unityCatalog.mcsc.initialCatalogParam.enabled': 'true',\n",
       " 'spark.databricks.delta.dbiManagedIcebergTable.enabled': 'true',\n",
       " 'spark.databricks.delta.logStore.crossCloud.fatal': 'true',\n",
       " 'spark.speculation.disabledForLocalCheckpoint.enabled': 'true',\n",
       " 'spark.databricks.dataLineage.mergeIntoV2Enabled': 'false',\n",
       " 'spark.databricks.photon.deletedRecordCountsHistogramAgg.enabled': 'false',\n",
       " 'spark.databricks.clusterUsageTags.hailEnabled': 'false',\n",
       " 'spark.databricks.cloudfiles.state.allowStreamingTableNonOwnerAccess': 'true',\n",
       " 'spark.databricks.service.dbutils.server.backend': 'com.databricks.dbconnect.SparkServerDBUtils',\n",
       " 'spark.databricks.dynamicConf.demoFlag14': 'false',\n",
       " 'spark.databricks.unityCatalog.enableUcSecretsDbUtils': 'false',\n",
       " 'spark.hadoop.fs.fcfs-s3a.impl': 'com.databricks.sql.acl.fs.FixedCredentialsFileSystem',\n",
       " 'spark.databricks.wsfs.workspacePrivatePreview': 'true',\n",
       " 'spark.databricks.isShieldWorkspace': 'false',\n",
       " 'spark.hadoop.fs.s3a.fast.upload.default': 'true',\n",
       " 'spark.databricks.delta.snapshotHint.supportUcExternalTables': 'false',\n",
       " 'spark.databricks.logging.queryProfile.captureAllAnalysisExceptions': 'false',\n",
       " 'spark.databricks.sql.optimizer.useStableResultMarkerForRuntimeFilters': 'true',\n",
       " 'spark.databricks.sql.internalHms.exponentialBackoff.enabled': 'true',\n",
       " 'spark.databricks.clusterUsageTags.instanceWorkerEnvNetworkType': 'default',\n",
       " 'spark.sql.warehouse.dir': 'dbfs:/user/hive/warehouse',\n",
       " 'spark.databricks.clusterUsageTags.attribute_tag_dust_execution_env': '',\n",
       " 'spark.databricks.optimizer.useOldSelectivityDetector': 'true',\n",
       " 'spark.speculation': 'false',\n",
       " 'spark.hadoop.databricks.dbfs.client.version': 'v2',\n",
       " 'spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.enabled': 'true',\n",
       " 'spark.databricks.unityCatalog.credentialManager.tokenRefreshEnabled': 'true',\n",
       " 'spark.databricks.clusterUsageTags.computeKind': 'CLASSIC_PREVIEW',\n",
       " 'spark.databricks.rewriteViewCatalogInUcOnlyMode': 'true',\n",
       " 'spark.databricks.clusterUsageTags.attribute_tag_budget': '',\n",
       " 'spark.databricks.sql.ignoreRedactNonUTF8Binary': 'true',\n",
       " 'spark.hadoop.databricks.fs.s3a.dmk.slowPathSampler.class': 'com.databricks.unity.DBRUCSHandleWrapper',\n",
       " 'spark.hadoop.hive.server2.use.SSL': 'true',\n",
       " 'spark.databricks.rowColumnControlsAllowlistRule.rule.enabled': 'false',\n",
       " 'spark.hadoop.fs.fcfs-s3a.impl.disable.cache': 'true',\n",
       " 'spark.databricks.safespark.ucPythonUDF.sandboxReuse.enabled': 'true',\n",
       " 'spark.databricks.adaptive.dfpExplicitScheduling.forHinted.ds': 'DISABLED',\n",
       " 'spark.hadoop.fs.idbfs.impl': 'com.databricks.io.idbfs.IdbfsFileSystem',\n",
       " 'spark.hadoop.spark.hadoop.aws.glue.cache.db.size': '1000',\n",
       " 'spark.driver.host': '10.139.64.4',\n",
       " 'spark.databricks.adaptive.dfp.explicitSchedulingOfBuildProbeSides': 'true',\n",
       " 'spark.databricks.clusterUsageTags.numPerClusterInitScriptsV2Workspace': '0',\n",
       " 'spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.scaleUpThresholdCurrentQpsIncreaseRatio': '0.0',\n",
       " 'spark.databricks.clusterUsageTags.attribute_tag_service': '',\n",
       " 'spark.databricks.dynamicConf.demoFlag10': 'false',\n",
       " 'spark.databricks.sql.optimizer.statisticsOnLoadTruncateColumnsAtLimit.enabled': 'true',\n",
       " 'spark.hadoop.fs.fcfs-wasbs.impl.disable.cache': 'true',\n",
       " 'spark.databricks.clusterUsageTags.userId': '146484896257728',\n",
       " 'spark.databricks.clusterUsageTags.userProvidedRemoteVolumeType': 'azure_disk_volume_type: PREMIUM_LRS\\n',\n",
       " 'spark.executor.extraJavaOptions': '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-modules=jdk.incubator.vector --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED --add-opens=jdk.jfr/jdk.jfr.internal.consumer=ALL-UNNAMED --add-opens=jdk.jfr/jdk.jfr.internal=ALL-UNNAMED --add-opens=java.management/sun.management=ALL-UNNAMED --add-opens=java.base/jdk.internal.loader=ALL-UNNAMED --add-opens=jdk.naming.dns/com.sun.jndi.dns=java.naming --add-opens=java.xml.crypto/com.sun.org.apache.xml.internal.security.utils=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false -Dio.netty.tryReflectionSetAccessible=true -Djava.security.manager=allow --enable-native-access=ALL-UNNAMED -Djava.io.tmpdir=/local_disk0/tmp -XX:ReservedCodeCacheSize=512m -XX:+UseCodeCacheFlushing -XX:PerMethodRecompilationCutoff=-1 -XX:PerBytecodeRecompilationCutoff=-1 -Djava.security.properties=/databricks/spark/dbconf/java/extra.security -XX:-UseContainerSupport -XX:+PrintFlagsFinal -Xlog:gc:stdout:time,uptime,level,tags -Xss4m -Djava.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni -Djavax.xml.datatype.DatatypeFactory=com.sun.org.apache.xerces.internal.jaxp.datatype.DatatypeFactoryImpl -Djavax.xml.parsers.DocumentBuilderFactory=com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderFactoryImpl -Djavax.xml.parsers.SAXParserFactory=com.sun.org.apache.xerces.internal.jaxp.SAXParserFactoryImpl -Djavax.xml.validation.SchemaFactory:http://www.w3.org/2001/XMLSchema=com.sun.org.apache.xerces.internal.jaxp.validation.XMLSchemaFactory -Dorg.xml.sax.driver=com.sun.org.apache.xerces.internal.parsers.SAXParser -Dorg.w3c.dom.DOMImplementationSourceList=com.sun.org.apache.xerces.internal.dom.DOMXSImplementationSourceImpl -Djavax.net.ssl.sessionCacheSize=10000 -Dscala.reflect.runtime.disable.typetag.cache=true -Dcom.google.cloud.spark.bigquery.repackaged.io.netty.tryReflectionSetAccessible=true -Dio.netty.tryReflectionSetAccessible=true -Dlog4j2.formatMsgNoLookups=true -XX:+UseBiasedLocking -XX:+IgnoreUnrecognizedVMOptions --add-modules=jdk.incubator.vector --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED --add-opens=jdk.jfr/jdk.jfr.internal.consumer=ALL-UNNAMED --add-opens=jdk.jfr/jdk.jfr.internal=ALL-UNNAMED --add-opens=java.management/sun.management=ALL-UNNAMED --add-opens=java.base/jdk.internal.loader=ALL-UNNAMED --add-opens=jdk.naming.dns/com.sun.jndi.dns=java.naming --add-opens=java.xml.crypto/com.sun.org.apache.xml.internal.security.utils=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false -Dio.netty.tryReflectionSetAccessible=true -Djava.security.manager=allow --enable-native-access=ALL-UNNAMED -XX:+UseParallelGC -Ddatabricks.serviceName=spark-executor-1',\n",
       " 'spark.sql.hive.convertMetastoreParquet': 'true',\n",
       " 'spark.scheduler.listenerbus.eventqueue.capacity': '20000',\n",
       " 'spark.serializer.objectStreamReset': '100',\n",
       " 'spark.databricks.sql.functions.aiFunctions.multiModality.model.list': 'databricks-llama-4-maverick,databricks-claude-sonnet-4,databricks-claude-3-7-sonnet,databricks-gemma-3-12b,databricks-gpt-5,databricks-gpt-5-mini,databricks-gpt-5-nano,databricks-gpt-5-1,databricks-gpt-5-2,databricks-gemini-2-5-flash,databricks-gemini-2-5-pro,databricks-gemini-3-flash,databricks-gemini-3-pro,databricks-claude-haiku-4-5',\n",
       " 'spark.databricks.session.share': 'false',\n",
       " 'spark.databricks.adaptive.forceCancelSkewedShuffleStageInBroadcastJoin.enabled': 'false',\n",
       " 'spark.databricks.io.cache.parquet.crc': 'true',\n",
       " 'spark.databricks.delta.sqlSnapshotReconstruction.removeRepartition': 'true',\n",
       " 'spark.databricks.sqlservice.history.queryParametersEnabled': 'true',\n",
       " 'spark.hadoop.fs.s3a.retry.interval': '250ms',\n",
       " 'spark.databricks.sql.jdbc.lakeguard.writes.enabled': 'false',\n",
       " 'spark.eventLog.enabled': 'false',\n",
       " 'spark.databricks.photon.fileSizeHistogramAgg.enabled': 'true',\n",
       " 'spark.r.backendConnectionTimeout': '604800',\n",
       " 'spark.databricks.secret.envVar.keys.toRedact': '',\n",
       " 'spark.databricks.metricAggregation.internalMetricsDagAggregation.enabled': 'false',\n",
       " 'spark.hadoop.fs.wasbs.impl.disable.cache': 'true',\n",
       " 'spark.databricks.tahoe.logStore.gcp.class': 'com.databricks.tahoe.store.GCPLogStore',\n",
       " 'spark.databricks.passthrough.adls.gen2.tokenProviderClassName': 'com.databricks.backend.daemon.data.client.adl.AdlGen2CredentialContextTokenProvider',\n",
       " 'spark.databricks.clusterUsageTags.driverInstancePrivateIp': '10.139.0.4',\n",
       " 'spark.databricks.clusterUsageTags.clusterNumCustomTags': '1',\n",
       " 'spark.hadoop.hive.hmshandler.retry.interval': '2000',\n",
       " 'spark.databricks.clusterUsageTags.clusterSizeType': 'VM_CONTAINER',\n",
       " 'spark.databricks.sql.streamingTable.sharedResolution.enabled': 'false',\n",
       " 'spark.databricks.dagScheduler.workItemMetricsEnabled': 'true',\n",
       " 'spark.databricks.logging.usage.migration.dualLogPercentProbabilitiesSparkCore': '{\"driverMetastoreEvent\":{\"lC\":0,\"lP\":100,\"uP\":100},\"metastoreUsage\":{\"lC\":100,\"lP\":100,\"uP\":0},\"mlMlAlgorithm\":{\"lC\":100,\"lP\":100,\"uP\":0},\"pandasOnSparkImported\":{\"lC\":100,\"lP\":100,\"uP\":0},\"sparkConnectOperationDuration\":{\"lC\":100,\"lP\":100,\"uP\":0},\"sparkJobEnd\":{\"lC\":100,\"lP\":100,\"uP\":0},\"sparkOperationDuration\":{\"lC\":100,\"lP\":100,\"uP\":0},\"sparkStageCompleted\":{\"lC\":100,\"lP\":100,\"uP\":0},\"tahoeEvent\":{\"lC\":0,\"lP\":100,\"uP\":100},\"queryExecutionCost\":{\"lC\":100,\"lP\":100,\"uP\":0}}',\n",
       " 'spark.hadoop.fs.s3a.multipart.threshold': '104857600',\n",
       " 'spark.aether.driver.id': 'driver',\n",
       " 'spark.shuffle.manager': 'SORT',\n",
       " 'spark.hadoop.fs.stage.impl': 'com.databricks.backend.daemon.driver.managedcatalog.PersonalStagingFileSystem',\n",
       " 'spark.hadoop.parquet.page.metadata.validation.enabled': 'true',\n",
       " 'spark.databricks.mlflow.autologging.enableGenAIFlavors': 'true',\n",
       " 'spark.hadoop.fs.wasb.impl': 'com.databricks.sql.io.LokiFileSystem',\n",
       " 'spark.streaming.driver.writeAheadLog.closeFileAfterWrite': 'true',\n",
       " 'spark.databricks.deltaSharing.shareWithHistoryByDefault': 'false',\n",
       " 'spark.databricks.cloudFiles.rocksDB.wal.ttlSeconds': '-1',\n",
       " 'spark.databricks.eventLog.listenerClassName': 'com.databricks.backend.daemon.driver.DBCEventLoggingListener',\n",
       " 'spark.databricks.sql.optimizer.ignoreUnsupportedTypesInAnalyze.enabled': 'true',\n",
       " 'spark.cleaner.referenceTracking.blocking': 'false',\n",
       " 'spark.databricks.clusterUsageTags.clusterNodeTypeFlexibilityEnabled': 'false',\n",
       " 'spark.databricks.clusterUsageTags.region': 'centralindia',\n",
       " 'spark.databricks.clusterUsageTags.ngrokNpipEnabled': 'true',\n",
       " 'spark.databricks.unityCatalog.samDerivation.enabled': 'false',\n",
       " 'spark.hadoop.fs.s3.impl': 'com.databricks.sql.io.LokiFileSystem',\n",
       " 'spark.databricks.delta.liquid.eagerClustering.aqeLateStage.fastPath.enabled': 'false',\n",
       " 'spark.databricks.clusterUsageTags.clusterSku': 'STANDARD_SKU',\n",
       " 'spark.databricks.sql.jdbc.enableLakeguardDriver': 'false',\n",
       " 'spark.databricks.acl.secureCatalogCheckUsageOnCatalog': 'true',\n",
       " 'spark.databricks.sql.redactSecretsInOptimizer': 'true',\n",
       " 'spark.databricks.clusterUsageTags.clusterGeneration': '1',\n",
       " 'spark.databricks.SC200982.blockBuiltInFunctionOverride': 'true',\n",
       " 'spark.databricks.safespark.externalUDF.env.installerObjectName': 'com.databricks.backend.daemon.driver.UDFEnvUtils',\n",
       " 'spark.databricks.sql.optimizer.statisticsOnLoadForPartitionColumns.enabled': 'true',\n",
       " 'spark.databricks.unityCatalog.includeTemporaryCredentialsInBulkGetMetadata': 'true',\n",
       " 'spark.databricks.optimizer.decorrelateQueriesWithStructFields.enabled': 'false',\n",
       " 'spark.sql.copyInto.timeout.threadDump.enabled': 'false',\n",
       " 'spark.driver.maxResultSize': '4g',\n",
       " 'spark.metrics.conf': '/databricks/spark/conf/metrics.properties',\n",
       " 'spark.databricks.hive.metastore.client.enableConnectionInfoLogging': 'true',\n",
       " 'spark.databricks.clusterUsageTags.clusterOwnerOrgId': '1046699569939209',\n",
       " 'spark.databricks.aether.dynamicScanDML.enabled': 'true',\n",
       " 'spark.hadoop.fs.cpfs-s3.impl': 'com.databricks.sql.acl.fs.CredentialPassthroughFileSystem',\n",
       " 'spark.databricks.clusterUsageTags.autoTerminationMinutes': '60',\n",
       " 'spark.databricks.sql.functions.aiFunctions.decimal.dataType.enabled': 'true',\n",
       " 'spark.databricks.telemetry.prometheus.samplingRate': '100',\n",
       " 'spark.hadoop.fs.adl.impl': 'com.databricks.sql.io.LokiFileSystem',\n",
       " 'spark.databricks.docingest.batchEval.size': '32',\n",
       " 'spark.databricks.io.parquet.readAfterWrite.mode': 'OFF',\n",
       " 'spark.hadoop.fs.abfss.impl.disable.cache': 'true',\n",
       " 'spark.databricks.clusterUsageTags.enableCredentialPassthrough': 'false',\n",
       " 'spark.hadoop.spark.driverproxy.customHeadersToProperties': 'X-Databricks-User-Token:spark.databricks.token,X-Databricks-Non-UC-User-Token:spark.databricks.non.uc.token,X-Databricks-Api-Url:spark.databricks.api.url,X-Databricks-ADLS-Gen1-Token:spark.databricks.adls.gen1.token,X-Databricks-ADLS-Gen2-Token:spark.databricks.adls.gen2.token,X-Databricks-Synapse-Token:spark.databricks.synapse.token,X-Databricks-AWS-Credentials:spark.databricks.aws.creds,X-Databricks-User-Id:spark.databricks.user.id,X-Databricks-User-Name:spark.databricks.user.name,X-Databricks-Oauth-Identity-Custom-Claim:spark.databricks.oauthCustomIdentityClaims,X-Databricks-Workload-Id:spark.databricks.workload.id,X-Databricks-Workload-Class:spark.databricks.workload.name,traceparent:spark.databricks.obs.traceparent.id,X-Databricks-UC-Metadata-Snapshot-Id:spark.databricks.unityCatalog.metadata.snapshot.id',\n",
       " 'spark.delta.sharing.query.includeEndStreamAction': 'true',\n",
       " 'spark.databricks.photon.cleanupResources.enabled': 'false',\n",
       " 'spark.databricks.credential.aws.secretKey.redactor': 'com.databricks.spark.util.AWSSecretKeyRedactorProxy',\n",
       " 'spark.databricks.eventLog.dir': 'eventlogs',\n",
       " 'spark.extraListeners': 'com.databricks.backend.daemon.driver.DBCEventLoggingListener',\n",
       " 'spark.databricks.managedCatalog.clientClassName': 'com.databricks.managedcatalog.ManagedCatalogClientImpl',\n",
       " 'spark.hadoop.hive.hmshandler.retry.attempts': '10',\n",
       " 'spark.databricks.photon.photonRowToColumnarSnowflakePlan.enabled': 'false',\n",
       " 'spark.databricks.clusterUsageTags.enableElasticDisk': 'true',\n",
       " 'spark.databricks.clusterUsageTags.ignoreTerminationEventInAlerting': 'false',\n",
       " 'spark.ui.port': '40001',\n",
       " 'spark.databricks.connector.teradata.connectionCharset': 'UTF8',\n",
       " 'spark.hadoop.fs.gs.outputstream.upload.chunk.size': '16777216',\n",
       " 'spark.sql.cte.recursion.enabled': 'true',\n",
       " 'spark.databricks.unityCatalog.clientWithCaller.enabled': 'true',\n",
       " 'spark.databricks.autotune.clusterByAuto.preview.enabled': 'true',\n",
       " 'spark.driver.port': '38819',\n",
       " 'spark.shuffle.reduceLocality.enabled': 'false',\n",
       " 'spark.shuffle.service.enabled': 'true',\n",
       " 'spark.databricks.sqlservice.history.sqlScriptCallStackLimit': '65535',\n",
       " 'spark.databricks.clusterUsageTags.isServicePrincipalCluster': 'false',\n",
       " 'spark.databricks.acl.provider': 'com.databricks.sql.acl.ReflectionBackedAclProvider',\n",
       " 'spark.databricks.safespark.ucPythonUDF.sandboxSharing.planning.enabled': 'true',\n",
       " 'spark.hadoop.hive.server2.keystore.password': '[REDACTED]',\n",
       " 'spark.rdd.compress': 'true',\n",
       " 'spark.databricks.instanceId': 'a7b177ffc8fd495e95656f5994daaad1',\n",
       " 'spark.databricks.sql.functions.aiQuery.openAI.oSeries.model.list': 'o1-mini,o1,o3-mini,o3,o4-mini,gpt-5,gpt-5-mini,gpt-5-nano,GPT-5,GPT-5 Mini,GPT-5 Nano',\n",
       " 'spark.databricks.remoteFiltering.enableServerlessSessionLocalPropagation': 'true',\n",
       " 'spark.databricks.sqlservice.history.isSqlgatewayHistoryProxyClientEnabled': 'true',\n",
       " 'spark.databricks.acl.enabled': 'false',\n",
       " 'spark.worker.aioaLazyConfig.iamReadinessCheckClientClass': 'com.databricks.backend.daemon.driver.NephosIamRoleCheckClient',\n",
       " 'spark.databricks.connector.bigquery.loadNamespaceFallbackEnabled': 'true',\n",
       " 'spark.databricks.docingest.logging.maxContentLength': '0',\n",
       " 'spark.hadoop.fs.file.impl': 'com.databricks.backend.daemon.driver.WorkspaceLocalFileSystem',\n",
       " 'spark.databricks.clusterUsageTags.userProvidedRemoteVolumeCount': '0',\n",
       " 'spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.scaleUpThresholdTotalQpsIncreaseRatio': '0.0',\n",
       " 'spark.databricks.clusterUsageTags.attribute_tag_dust_runner': '',\n",
       " 'spark.databricks.eventLog.enabled': 'true',\n",
       " 'spark.databricks.sql.fsUtils.listShadowingSampleRate': '0.2',\n",
       " 'spark.databricks.clusterUsageTags.userProvidedRemoteVolumeSizeGb': '0',\n",
       " 'spark.databricks.passthrough.glue.credentialsProviderFactoryClassName': 'com.databricks.backend.daemon.driver.credentials.DatabricksCredentialProviderFactory',\n",
       " 'spark.hadoop.fs.mlflowdbfs.impl': 'com.databricks.mlflowdbfs.MlflowdbfsFileSystem',\n",
       " 'spark.databricks.autotune.maintenance.enableColumnUsageTrackingIntegration': 'true',\n",
       " 'spark.databricks.delta.optimizeMetadataQuery.clusteredTable.enabled': 'true',\n",
       " 'spark.databricks.sql.optimizer.ensureRequirementsDP.tracing': 'false',\n",
       " 'spark.databricks.redactor': 'com.databricks.spark.util.DatabricksSparkLogRedactorProxy',\n",
       " 'spark.databricks.clusterUsageTags.driverInstanceId': 'a7b177ffc8fd495e95656f5994daaad1',\n",
       " 'spark.hadoop.fs.s3a.vectored.read.min.seek.size': '128K',\n",
       " 'spark.databricks.clusterUsageTags.privateLinkEnabled': 'false',\n",
       " 'spark.databricks.unityCatalog.sftpConnection.enabled': 'true',\n",
       " 'spark.repl.class.uri': 'spark://10.139.64.4:38819/classes',\n",
       " 'spark.databricks.clusterUsageTags.sparkEnvVarContainsBacktick': 'false',\n",
       " 'spark.databricks.sql.optimizer.statisticsOnLoadWithSchemaEvolution.enabled': 'true',\n",
       " 'spark.hadoop.spark.databricks.metrics.filesystem_metrics': 'true',\n",
       " 'spark.databricks.clusterUsageTags.clusterFirstOnDemand': '1',\n",
       " 'spark.databricks.adaptive.dppExplicitScheduling.broadcastJoins.enabled': 'true',\n",
       " 'spark.databricks.passthrough.s3a.threadPoolExecutor.factory.class': 'com.databricks.backend.daemon.driver.aws.S3APassthroughThreadPoolExecutorFactory',\n",
       " 'spark.databricks.clusterUsageTags.sparkVersion': '17.3.x-photon-scala2.13',\n",
       " 'spark.hadoop.parquet.memory.pool.ratio': '0.5',\n",
       " 'spark.databricks.clusterUsageTags.clusterName': 'f1-databricks-cluster-dev',\n",
       " 'spark.hadoop.fs.fcfs-abfss.impl': 'com.databricks.sql.acl.fs.FixedCredentialsFileSystem',\n",
       " 'spark.databricks.sql.optimizer.analyzeTruncateColumnsAtLimit.enabled': 'true',\n",
       " 'spark.databricks.metricAggregation.stageLevelMetricsAggregationOnTheDAGScheduler.enabled': 'false',\n",
       " 'spark.databricks.deltaSharing.createShareWithBudgetPolicy': 'true',\n",
       " 'spark.databricks.delta.update.metrics.computationInFilters': 'false',\n",
       " 'spark.databricks.credential.scope.fs.adls.gen2.tokenProviderClassName': 'com.databricks.backend.daemon.driver.credentials.CredentialScopeADLSTokenProvider',\n",
       " 'spark.databricks.clusterUsageTags.isSingleNode': 'true',\n",
       " 'spark.hadoop.fs.stage.impl.disable.cache': 'true',\n",
       " 'spark.driver.tempDirectory': '/local_disk0/tmp',\n",
       " 'spark.databricks.credential.scope.fs.gs.auth.access.tokenProviderClassName': 'com.databricks.backend.daemon.driver.credentials.CredentialScopeGCPTokenProvider',\n",
       " 'spark.databricks.wsfs.workspaceNotebookCwd': 'true',\n",
       " 'spark.hadoop.fs.abfs.impl': 'com.databricks.sql.io.LokiFileSystem',\n",
       " 'spark.delta.sharing.profile.provider.class': 'io.delta.sharing.DeltaSharingCredentialsProvider',\n",
       " 'spark.hadoop.fs.wasbs.impl': 'com.databricks.sql.io.LokiFileSystem',\n",
       " 'spark.hadoop.fs.fcfs-s3.impl': 'com.databricks.sql.acl.fs.FixedCredentialsFileSystem',\n",
       " 'spark.databricks.dlt.mvAsTable.enabled': 'false',\n",
       " 'spark.databricks.unityCatalog.mcsc.unityCatalogEnabledParam.enabled': 'false',\n",
       " 'spark.databricks.unityCatalog.ucSecretsDdl.enabled': 'false',\n",
       " 'spark.databricks.sql.optimizer.statsOnDataLoadWithRowidTracking.enabled': 'true',\n",
       " 'spark.databricks.delta.unsetManaged.timeWindowInDays': '14',\n",
       " 'spark.databricks.docingest.version.supported': '2.0',\n",
       " 'spark.databricks.clusterUsageTags.clusterState': 'Pending',\n",
       " 'spark.hadoop.fs.s3a.impl.disable.cache': 'true',\n",
       " 'spark.databricks.clusterUsageTags.clusterUnityCatalogMode': 'LEGACY_SINGLE_USER_STANDARD',\n",
       " 'spark.databricks.credential.scope.fs.onelake.tokenProviderClassName': 'com.databricks.backend.daemon.driver.credentials.CredentialScopeOneLakeTokenProvider',\n",
       " 'spark.sql.analyzer.dontDeduplicateExpressionIfExprIdInOutput': 'false',\n",
       " 'spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.scaleUpThresholdSuccessRatio': '0.95',\n",
       " 'libraryDownload.timeoutSeconds': '180',\n",
       " 'spark.databricks.delta.dataskipping.supportToTimestampExprs.enabled': 'true',\n",
       " 'spark.databricks.sql.semanticMetadata.describe.enabled': 'true',\n",
       " 'spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version': '2',\n",
       " 'spark.databricks.deltaSharing.clientClassName': 'com.databricks.deltasharing.DataSharingClientImpl',\n",
       " 'spark.databricks.sql.optimizer.AnalyzeTableStalenessThreshold': '0',\n",
       " 'spark.databricks.aether.fixedPort.enabled': 'true',\n",
       " 'spark.databricks.sqlservice.history.isWisErrorDiagnosticInfoTruncationEnabled': 'true',\n",
       " 'spark.databricks.adaptive.dppExplicitScheduling.forHinted.ds': 'DISABLED',\n",
       " 'spark.databricks.sqlgateway.history.profile.backgroundBuildEnabled': 'true',\n",
       " 'spark.worker.aioaLazyConfig.dbfsReadinessCheckClientClass': 'com.databricks.backend.daemon.driver.NephosDbfsReadinessCheckClient',\n",
       " 'spark.databricks.unityCatalog.http.client.minRetryIntervalMs': '500',\n",
       " 'spark.databricks.clusterUsageTags.clusterTargetWorkers': '0',\n",
       " 'spark.databricks.sql.functions.aiFunctions.purposeBuiltFunctions.batch.execution.enabled': 'true',\n",
       " 'spark.databricks.shuffle.cleanupResources.enabled': 'false',\n",
       " 'spark.databricks.sql.functions.aiFunctions.safe.inference.enabled': 'true',\n",
       " 'spark.databricks.delta.liquid.lazyClustering.shuffle.preferDataFrameInterface': 'false',\n",
       " 'spark.databricks.sql.metricView.yaml.v11.enabled': 'true',\n",
       " 'spark.hadoop.fs.fcfs-abfss.impl.disable.cache': 'true',\n",
       " 'spark.databricks.io.cache.initialDiskSize': '161061273600',\n",
       " 'spark.databricks.unityCatalog.connectionDfOptionInjection.enabled': 'false',\n",
       " 'spark.databricks.driverNfs.pathSuffix': '.ephemeral_nfs',\n",
       " 'spark.databricks.pipelines.allowAlterNonDBSQLPipeline': 'true',\n",
       " 'spark.databricks.sql.functions.aiFunctions.batch.execution.size': '2048',\n",
       " 'spark.databricks.passthrough.oauth.refresher.impl': 'com.databricks.backend.daemon.driver.credentials.OAuthTokenRefresherClient',\n",
       " 'spark.connect.extensions.relation.classes': 'io.delta.connect.DeltaRelationPlugin,com.databricks.spark.connect.plugin.DbutilsRelationPlugin',\n",
       " 'spark.repl.class.outputDir': '/local_disk0/tmp/repl/spark-6597697878895198200-c0c9df5f-b98c-4c5d-8069-9579883717aa',\n",
       " 'spark.databricks.adaptive.dfpExplicitSchedulingWithRBF.enabled': 'false',\n",
       " 'spark.databricks.clusterUsageTags.workerEnvironmentId': 'workerenv-1046699569939209',\n",
       " 'spark.app.name': 'Databricks Shell',\n",
       " 'spark.connect.grpc.binding.port': '15002',\n",
       " 'spark.databricks.wsfsPublicPreview': 'true',\n",
       " 'spark.databricks.credential.redactor': 'com.databricks.logging.secrets.CredentialRedactorProxyImpl',\n",
       " 'spark.databricks.cloudFiles.rocksDB.wal.sizeLimitMB': '0',\n",
       " 'spark.hadoop.fs.abfss.impl': 'com.databricks.sql.io.LokiFileSystem',\n",
       " 'spark.hadoop.hive.warehouse.subdir.inherit.perms': 'false',\n",
       " 'spark.databricks.optimizer.rankFilterEarlyStop.unpartitioned.maxLimit': '50000',\n",
       " 'spark.databricks.delta.incrementalSmallTable.cache.enabled': 'false',\n",
       " 'spark.databricks.connector.sqldw.quoteIdentifiersLakehouseFederation': 'true',\n",
       " 'spark.databricks.sql.functions.aiFunctions.vectorSearch.initialRetryIntervalMillis': '1000',\n",
       " 'spark.hadoop.fs.fcfs-wasb.impl.disable.cache': 'true',\n",
       " 'spark.connect.extensions.command.classes': 'io.delta.connect.DeltaCommandPlugin,com.databricks.spark.connect.plugin.QueryHistoryCommandPlugin',\n",
       " 'spark.databricks.sql.view.legacy.schemaEvolution': 'false',\n",
       " 'spark.sql.hive.metastore.jars': '/databricks/databricks-hive/*',\n",
       " 'spark.sql.parquet.cacheMetadata': 'true',\n",
       " 'spark.databricks.sql.udf.connectionEnvironmentSettings.enabled': 'false',\n",
       " 'spark.hadoop.fs.cpfs-abfss.impl': 'com.databricks.sql.acl.fs.CredentialPassthroughFileSystem',\n",
       " 'spark.databricks.optimizer.structSizeInBytesEstimateIncludeSchemaPruning.enabled': 'true',\n",
       " 'spark.hadoop.fs.fcfs-wasb.impl': 'com.databricks.sql.acl.fs.FixedCredentialsFileSystem',\n",
       " 'spark.storage.blockManagerTimeoutIntervalMs': '300000',\n",
       " 'spark.databricks.service.dbutils.repl.backend': 'com.databricks.dbconnect.ReplDBUtils',\n",
       " 'spark.databricks.autotune.maintenance.enableMetricsForAllUCManagedTables': 'true',\n",
       " 'spark.hadoop.fs.s3a.connection.timeout': '50000',\n",
       " 'spark.r.numRBackendThreads': '1',\n",
       " 'spark.memory.offHeap.enabled': 'true',\n",
       " 'spark.hadoop.fs.s3a.vectored.read.max.merged.size': '2M',\n",
       " 'spark.hadoop.hive.server2.thrift.http.cookie.auth.enabled': 'false',\n",
       " 'spark.databricks.clusterUsageTags.attribute_tag_dust_runbot_id': '',\n",
       " 'spark.hadoop.fs.s3a.multipart.size': '10485760',\n",
       " 'spark.hadoop.fs.s3a.connection.maximum': '200',\n",
       " 'spark.databricks.clusterUsageTags.numPerGlobalInitScriptsV2': '0',\n",
       " 'spark.databricks.sql.functions.aiFunctions.batchSession.terminate.enabled': 'true',\n",
       " 'spark.databricks.photon.hllUnionAggGroupingNonGrouping.enabled': 'false',\n",
       " 'spark.databricks.credential.scope.fs.r2.tokenProviderClassName': 'com.databricks.backend.daemon.driver.credentials.CredentialScopeR2TokenProvider',\n",
       " 'spark.databricks.unityCatalog.clientClassName': 'com.databricks.managedcatalog.ManagedCatalogClientImpl',\n",
       " 'spark.databricks.sql.allowDroppingDLTMaterializedViewStreamingTable': 'true',\n",
       " 'spark.databricks.delta.uniform.ingress.enableOnFederation.sfdc': 'true',\n",
       " 'spark.databricks.sql.rowColumnAccess.castOnAbacColumnTypeMismatch.enabled': 'true',\n",
       " 'spark.databricks.delta.alterTableUnsetManaged.enabled': 'true',\n",
       " 'spark.hadoop.parquet.block.size.row.check.min': '10',\n",
       " 'spark.databricks.sql.externalUDF.clientImage.enabled': 'false',\n",
       " 'spark.databricks.sql.udf.routineEnvironmentSettings.enabled': 'true',\n",
       " 'spark.databricks.sql.tempTable.blockDatabricksJobs': 'false',\n",
       " 'spark.databricks.secret.sparkConf.keys.toRedact': '',\n",
       " 'spark.scheduler.mode': 'FAIR',\n",
       " 'spark.hadoop.fs.s3.impl.disable.cache': 'true',\n",
       " 'spark.databricks.fs.azure.shared.threadpool.enabled': 'false',\n",
       " 'spark.storage.memoryFraction': '0.5',\n",
       " 'spark.databricks.sql.functions.aiFunctions.vectorSearch.retryIntervalMultiplierFactor': '2.0',\n",
       " 'spark.databricks.delta.usageLogging.latencyAccumulatorMetrics': 'true',\n",
       " 'spark.databricks.io.parquet.rowBased.nativeFrameReader.taskSamplePercent': '0',\n",
       " 'spark.databricks.delta.dataskipping.supportTimestampDiff.enabled': 'false',\n",
       " 'spark.databricks.sql.externalUDF.clientImage.supportedMinVersion': '3',\n",
       " 'spark.databricks.unityCatalog.hms.federation.enableDbfsSupport': 'true',\n",
       " 'spark.hadoop.fs.fcfs-abfs.impl.disable.cache': 'true',\n",
       " 'spark.databricks.clusterUsageTags.clusterLastActivityTime': '1765872356937',\n",
       " 'spark.databricks.clusterUsageTags.managedResourceGroup': 'databricks-rg-adb-formula1-dev-5xzrrhrt2w6n6',\n",
       " 'spark.databricks.gdrive.fileSystem.enabled': 'false',\n",
       " 'spark.databricks.sqlservice.history.sqlScriptBatchEnabled': 'true',\n",
       " 'spark.databricks.autotune.maintenance.ucPoNonAuto.scanMetric.sampleRate': '0.2',\n",
       " 'spark.databricks.clusterSource': 'UI',\n",
       " 'spark.databricks.prefetchingReader.json.enabled': 'true',\n",
       " 'spark.databricks.acl.scim.client': 'com.databricks.spark.sql.acl.client.DriverToWebappScimClient',\n",
       " 'spark.databricks.rowColumnControlsAllowlistLogs.enabled': 'false',\n",
       " 'spark.databricks.overrideDefaultCommitProtocol': 'org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol',\n",
       " 'spark.databricks.clusterUsageTags.isIMv2Enabled': 'true',\n",
       " 'spark.databricks.clusterUsageTags.sparkMasterUrlType': 'Local',\n",
       " 'spark.databricks.repl.enableClassFileCleanup': 'true',\n",
       " 'spark.databricks.optimizer.bloomFilter.disableIfReducingBhjOverApplicationSide': 'false',\n",
       " 'spark.databricks.clusterUsageTags.clusterId': '1216-080236-r9lzzt0b',\n",
       " 'spark.databricks.cloudFiles.csms.preview.enabled': 'true',\n",
       " 'spark.databricks.clusterUsageTags.attribute_tag_dust_resource_class': '',\n",
       " 'spark.databricks.passthrough.adls.tokenProviderClassName': 'com.databricks.backend.daemon.data.client.adl.AdlCredentialContextTokenProvider',\n",
       " 'spark.hadoop.parquet.abfs.readahead.optimization.enabled': 'true',\n",
       " 'spark.databricks.privateLinkEnabled': 'false',\n",
       " 'spark.databricks.sql.metricView.temporary.enabled': 'true',\n",
       " 'spark.sql.hive.convertCTAS': 'true',\n",
       " 'spark.hadoop.spark.databricks.io.parquet.verifyChecksumOnWrite.throwsException': 'false',\n",
       " 'spark.databricks.clusterUsageTags.clusterMetastoreAccessType': 'RDS_DIRECT',\n",
       " 'spark.databricks.photon.topk.offset.enabled': 'false',\n",
       " 'spark.task.reaper.exitCausedByApp': 'false',\n",
       " 'spark.hadoop.fs.s3a.attempts.maximum': '10',\n",
       " 'spark.files.fetchFailure.unRegisterOutputOnHost': 'true',\n",
       " 'spark.databricks.unityCatalog.credentialManager.apiTokenProviderClassName': 'com.databricks.unity.TokenServiceApiTokenProvider',\n",
       " 'spark.databricks.clusterUsageTags.enableGlueCatalogCredentialPassthrough': 'false',\n",
       " 'spark.databricks.metrics.filesystem_io_metrics': 'true',\n",
       " 'spark.hadoop.fs.s3a.max.total.tasks': '1000',\n",
       " 'spark.databricks.delta.versionedDeepClone.cloneInProgress.enabled': 'false',\n",
       " 'spark.databricks.proxyHadoopTraffic.port': '9210',\n",
       " 'spark.databricks.delta.vacuum.entityStorageLocation.enabled': 'true',\n",
       " 'spark.databricks.autotune.maintenance.pushCompleteWorkloadScanMetrics': 'true',\n",
       " 'spark.databricks.cloudFiles.listingV2.enabled': 'false',\n",
       " 'spark.databricks.sql.externalUDF.env.enabled': 'true',\n",
       " 'spark.memory.offHeap.size': '6978273280',\n",
       " 'spark.databricks.io.native.s3.write.taskSamplePercent': '0',\n",
       " 'spark.logConf': 'true',\n",
       " 'spark.hadoop.parquet.block.size.row.check.max': '10',\n",
       " 'spark.databricks.clusterUsageTags.clusterCreator': 'Webapp',\n",
       " 'spark.databricks.tahoe.logStore.class': 'com.databricks.tahoe.store.DelegatingLogStore',\n",
       " 'spark.hadoop.parquet.filter.columnindex.enabled': 'false',\n",
       " 'spark.databricks.credential.scope.fs.s3a.tokenProviderClassName': 'com.databricks.backend.daemon.driver.credentials.CredentialScopeS3TokenProvider',\n",
       " 'spark.databricks.mlflow.autologging.enabled': 'true',\n",
       " 'spark.databricks.sql.functions.aiFunctions.batchInferenceApi.enabled': 'true',\n",
       " 'spark.databricks.acl.secureCatalogBatchFilterDatabases': 'true',\n",
       " 'spark.databricks.pipelines.moveTableBetweenPipelines.materializedView.enabled': 'true',\n",
       " 'spark.databricks.delta.skipping.enhancedIsNullPushdownExprs.enabled': 'false',\n",
       " 'spark.delta.sharing.network.useAsyncQuery': 'false',\n",
       " 'spark.databricks.optimizer.doNotMergeInvalidAutoStatistics.enabled': 'true',\n",
       " 'spark.databricks.unityCatalog.enableUcSecretsDdl': 'true',\n",
       " 'spark.databricks.sql.jdbcDialectForbidQueriesWithForbiddenKeywords': 'true',\n",
       " 'spark.worker.cleanup.enabled': 'false',\n",
       " 'spark.hadoop.fs.fcfs-wasbs.impl': 'com.databricks.sql.acl.fs.FixedCredentialsFileSystem',\n",
       " 'spark.executor.tempDirectory': '/local_disk0/tmp',\n",
       " 'spark.databricks.sql.optimizer.collectWorkloadBasedDataSkipping.enabled': 'true',\n",
       " 'spark.databricks.acl.dfAclsEnabled': 'false',\n",
       " 'spark.databricks.sparkContextId': '6597697878895198200',\n",
       " 'spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.maxPoolSize.aiParseDocument': '64',\n",
       " 'spark.hadoop.fs.s3n.impl.disable.cache': 'true',\n",
       " 'spark.databricks.shuffle.service.native.client.migration.enabled': 'false',\n",
       " 'spark.databricks.unityCatalog.client.UCSEWithMessageTemplateAndClass.enabled': 'true',\n",
       " 'spark.databricks.driverNodeTypeId': 'Standard_D4ds_v5',\n",
       " 'spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.maxPoolSize': '2048',\n",
       " 'spark.databricks.sql.optimizer.storeOptimizerStatsForStructField.enabled': 'false',\n",
       " 'spark.databricks.sse.dmk.overrideMetadataUcEntityId.enabled': 'true',\n",
       " 'libraryDownload.sleepIntervalSeconds': '5',\n",
       " 'spark.databricks.clusterUsageTags.sparkImageLabel': 'release__17.3.x-snapshot-photon-scala2.13__databricks__17.3.2__7a71a60__337e88b__jenkins__639b57d__format-3',\n",
       " 'spark.databricks.sqlservice.history.enableSessionScopedQueryStatusPublish': 'true',\n",
       " 'spark.databricks.nativeStackTraceInThreadDump.enabled': 'true',\n",
       " 'spark.hadoop.databricks.s3.verifyBucketExists.enabled': 'false',\n",
       " 'spark.databricks.prefetchingReader.compressedFiles.enabled': 'false',\n",
       " 'spark.databricks.clusterUsageTags.sparkEnvVarContainsDoubleQuotes': 'false',\n",
       " 'spark.hadoop.hive.server2.idle.operation.timeout': '7200000',\n",
       " 'spark.speculation.multiplier': '3',\n",
       " 'spark.task.reaper.enabled': 'true',\n",
       " 'spark.databricks.fs.wasb.writes.etag.enabled': 'true',\n",
       " 'spark.databricks.unityCatalog.forceMetadataSnapshotBatchUpdate': 'false',\n",
       " 'spark.databricks.unityCatalog.warmupEnabled': 'false',\n",
       " 'spark.databricks.reyden.saferSessionTest': '2',\n",
       " 'spark.sql.optimizer.optimizeCsvJsonExprs.useSchemaField': 'false',\n",
       " 'spark.databricks.driverNfs.enabled': 'true',\n",
       " 'spark.databricks.delta.writePartitionColumnsToParquet': 'true',\n",
       " 'spark.debugger.gcMonitor.shouldSendProductEventLog': 'true',\n",
       " 'spark.hadoop.hive.server2.session.check.interval': '60000',\n",
       " 'spark.databricks.sql.optimizer.statisticsOnLoadWithColumnMapping.enabled': 'true',\n",
       " 'spark.databricks.clusterUsageTags.driverContainerPrivateIp': '10.139.64.4',\n",
       " 'spark.sql.streaming.checkpointFileManagerClass': 'com.databricks.spark.sql.streaming.DatabricksCheckpointFileManager',\n",
       " 'spark.databricks.docingest.client.v2.enabled': 'true',\n",
       " 'spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.debugLogEnabled': 'true',\n",
       " 'spark.databricks.photon.bitmapAggregator.enabled': 'false',\n",
       " 'spark.databricks.thriftserver.enableComplexTypeNullParameters.enabled': 'false',\n",
       " 'spark.sql.streaming.stopTimeout': '15s',\n",
       " 'spark.databricks.remoteFiltering.sendBillingInfo': 'true',\n",
       " 'spark.databricks.sql.optimizer.bloomFilterRuntimeValidation.enabled': 'true',\n",
       " 'spark.databricks.optimizer.optimizeLimit.maxLimit': '10001',\n",
       " 'spark.databricks.sqlservice.history.processExecutorMetricsUpdate': 'true',\n",
       " 'spark.databricks.docingest.stage2.descriptionModel': 'databricks-gemma-3-12b',\n",
       " 'spark.databricks.sqlservice.history.metricPolling.runIntervalMs': '0',\n",
       " 'spark.connect.session.planCompression.threshold': '10485760',\n",
       " 'spark.hadoop.fs.dbfs.impl': 'com.databricks.sql.io.LokiFileSystem',\n",
       " 'spark.databricks.delta.changeDataFeed.readTimeCDCReader.enabled': 'false',\n",
       " 'spark.databricks.sql.expression.aiFunctions.repartition': '0',\n",
       " 'spark.app.startTime': '1765880132318',\n",
       " 'spark.databricks.sql.scripting.executionV2.enabled': 'true',\n",
       " 'spark.executor.id': 'driver',\n",
       " 'spark.databricks.unityCatalog.legacy.enableCrossScopeCredCache': 'true',\n",
       " 'spark.databricks.adaptive.dfpExplicitScheduling.broadcastJoins.enabled': 'true',\n",
       " 'spark.delta.sharing.client.sparkParquetIOCache.enabled': 'true',\n",
       " 'spark.hadoop.databricks.s3commit.client.sslTrustAll': 'false',\n",
       " 'spark.databricks.sql.ES_1355131': 'false',\n",
       " 'spark.databricks.photon.maxMinByNestedTypes.enabled': 'false',\n",
       " 'databricks.sqlgateway.history.queryParametersByteLimit': '51200',\n",
       " 'spark.databricks.driver.cleanUpSparkSessionsOnUCSharedClusters': 'true',\n",
       " 'spark.databricks.driver.preferredMavenCentralMirrorUrl': 'https://maven-central.storage-download.googleapis.com/maven2/',\n",
       " 'spark.databricks.driver.enableDncOomMessage': 'false',\n",
       " 'spark.databricks.delta.partitionedTable.staticScan.allowed': 'false',\n",
       " 'spark.databricks.sql.functions.externalUDFs.trackedAsDependency': 'false',\n",
       " 'spark.hadoop.spark.hadoop.aws.glue.cache.table.size': '1000',\n",
       " 'spark.hadoop.hive.server2.idle.session.timeout': '900000',\n",
       " 'spark.hadoop.fs.cpfs-abfss.impl.disable.cache': 'true',\n",
       " 'spark.hadoop.fs.s3a.retry.limit': '6',\n",
       " 'spark.databricks.enablePublicDbfsFuse': 'false',\n",
       " 'spark.databricks.clusterUsageTags.sparkEnvVarContainsNewline': 'false',\n",
       " 'spark.databricks.clusterUsageTags.clusterPinned': 'false',\n",
       " 'spark.hadoop.fs.fcfs-s3n.impl': 'com.databricks.sql.acl.fs.FixedCredentialsFileSystem',\n",
       " 'spark.databricks.sql.optimizer.discardColumnStatsWithTooLongKeys.enabled': 'true',\n",
       " 'spark.databricks.autotune.maintenance.client.clusterScoped.asyncForcePush.enabled': 'true',\n",
       " 'spark.databricks.dlt.externalMetadata.refreshPolicy': 'ALL_HISTORY',\n",
       " 'spark.databricks.hangingThreadDetector.enabled': 'true',\n",
       " 'spark.databricks.sql.functions.vectorSearch.use.indexIdentifierOnly': 'true',\n",
       " 'spark.databricks.io.native.s3.head.taskSamplePercent': '0',\n",
       " 'spark.hadoop.hive.server2.thrift.http.port': '10000',\n",
       " 'spark.databricks.unityCatalog.hmsDisabledInfoLogging.enabled': 'true',\n",
       " 'spark.databricks.photon.outputHashCodeForBloomFilter.enabled': 'false',\n",
       " 'spark.databricks.catalog.hiveMetastorePlaceholderPathFixForDbfs.enabled': 'true',\n",
       " 'spark.hadoop.fs.dbfsartifacts.impl': 'com.databricks.backend.daemon.data.client.DBFSV1',\n",
       " 'spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.useDynamicTaskQueueExecutor': 'false',\n",
       " 'spark.databricks.clusterUsageTags.isGroupCluster': 'false',\n",
       " 'spark.databricks.sql.rowColumnAccess.implicitPoliciesNew.enabled': 'true',\n",
       " 'spark.databricks.abTesting.client.httpClientClass': 'com.databricks.common.client.DreamcatcherRuntimeHttpClient',\n",
       " 'spark.databricks.io.directoryCommit.enableLogicalDelete': 'false',\n",
       " 'spark.databricks.delta.commandInvariantChecksThrowInUpdate': 'false',\n",
       " 'spark.databricks.unityCatalog.ucSecretsDbUtils.enabled': 'false',\n",
       " 'spark.databricks.clusterUsageTags.clusterLogDestination': '',\n",
       " 'spark.databricks.delta.dataskipping.supportConvertTimezone.enabled': 'true',\n",
       " 'spark.hadoop.parquet.page.verify-checksum.enabled': 'true',\n",
       " 'spark.databricks.delta.deltaLogUpdate.useHeadForUcManagedTables': 'true',\n",
       " 'spark.databricks.delta.incrementalChecksumOnRead.numCommitsThreshold': '20',\n",
       " 'spark.databricks.clusterUsageTags.instanceWorkerEnvId': 'workerenv-1046699569939209',\n",
       " 'spark.driver.extraJavaOptions': '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-modules=jdk.incubator.vector --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED --add-opens=jdk.jfr/jdk.jfr.internal.consumer=ALL-UNNAMED --add-opens=jdk.jfr/jdk.jfr.internal=ALL-UNNAMED --add-opens=java.management/sun.management=ALL-UNNAMED --add-opens=java.base/jdk.internal.loader=ALL-UNNAMED --add-opens=jdk.naming.dns/com.sun.jndi.dns=java.naming --add-opens=java.xml.crypto/com.sun.org.apache.xml.internal.security.utils=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false -Dio.netty.tryReflectionSetAccessible=true -Djava.security.manager=allow --enable-native-access=ALL-UNNAMED',\n",
       " 'spark.databricks.delta.identifierExtraction.newCodePath.enabled': 'true',\n",
       " 'spark.databricks.clusterUsageTags.enableJobsAutostart': 'true',\n",
       " 'spark.hadoop.fs.azure.authorization.caching.enable': 'false',\n",
       " 'spark.hadoop.fs.r2.impl.disable.cache': 'true',\n",
       " 'spark.databricks.io.native.adlgen2.write.taskSamplePercent': '100',\n",
       " 'spark.databricks.delta.spark.databricks.execution.resultCaching.versionChangeCheckEnabled': 'log-only',\n",
       " 'spark.databricks.unityCatalog.allowSetHmsCatalog': 'true',\n",
       " 'spark.databricks.delta.variant.forceUsePreviewTableFeature': 'true',\n",
       " 'spark.databricks.io.cache.autocompression.instance.overrides': '{}',\n",
       " 'spark.databricks.clusterUsageTags.clusterResourceClass': 'SingleNode',\n",
       " 'spark.databricks.logging.queryProfile.skipSizeInBytes': 'true',\n",
       " 'spark.databricks.table.parquet.compression.codec.enabled': 'true',\n",
       " 'spark.databricks.universe.commandContextFactory.class': 'com.databricks.spark.util.UniverseCommandContextFactoryImpl',\n",
       " 'spark.databricks.unityCatalog.hms.federation.enabled': 'true',\n",
       " 'spark.shuffle.service.port': '4048',\n",
       " 'spark.databricks.passthrough.glue.executorServiceFactoryClassName': 'com.databricks.backend.daemon.driver.credentials.GlueClientExecutorServiceFactory',\n",
       " 'spark.databricks.sharepoint.fileSystem.enabled': 'false',\n",
       " 'spark.databricks.prefetchingReader.xml.enabled': 'true',\n",
       " 'spark.databricks.safer.dimensionVerificationFlag': '30',\n",
       " 'spark.sql.legacy.createHiveTableByDefault': 'false',\n",
       " 'spark.databricks.dynamicConf.saca.killswitch-rampup-bool': 'true',\n",
       " 'spark.databricks.clusterUsageTags.userProvidedSparkVersion': '17.3.x-scala2.13',\n",
       " 'spark.databricks.io.native.gcs.read.taskSamplePercent': '100',\n",
       " 'spark.databricks.clusterUsageTags.enableJdbcAutoStart': 'true',\n",
       " 'spark.databricks.sql.optimizer.requireStronglyConsistentStatsForDataSkipping.enabled': 'true',\n",
       " 'spark.databricks.abTesting.leadSampleRate': '0.2',\n",
       " 'spark.databricks.sql.optimizer.includeAllDMLForPredictiveAnalyzeMetrics': 'true',\n",
       " 'spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.taskWaitTimeInSeconds': '1000',\n",
       " 'spark.hadoop.fs.cpfs-s3n.impl': 'com.databricks.sql.acl.fs.CredentialPassthroughFileSystem',\n",
       " 'spark.databricks.docingest.version.default': '2.0',\n",
       " 'spark.databricks.acl.client': 'com.databricks.spark.sql.acl.client.SparkSqlAclClient',\n",
       " 'spark.databricks.unityCatalog.lakehouseFederation.writes.enabled': 'true',\n",
       " 'spark.databricks.delta.deltaCommitSummary.refreshOnMiss.enabled': 'false',\n",
       " 'spark.databricks.docingest.pagination.concurrency': '4',\n",
       " 'spark.databricks.clusterUsageTags.sparkEnvVarContainsDollarSign': 'false',\n",
       " 'spark.databricks.clusterUsageTags.numPerClusterInitScriptsV2Dbfs': '0',\n",
       " 'spark.databricks.clusterUsageTags.clusterStateMessage': 'Starting Spark',\n",
       " 'spark.databricks.sql.metricView.materializations.enabled': 'true',\n",
       " 'spark.master': 'local[*, 4]',\n",
       " 'spark.hadoop.fs.s3a.block.size': '67108864',\n",
       " 'spark.databricks.tahoe.logStore.aws.class': 'com.databricks.tahoe.store.MultiClusterLogStore',\n",
       " 'spark.databricks.sql.functions.vectorSearch.enabled': 'true',\n",
       " 'spark.databricks.clusterUsageTags.attribute_tag_platform_name': '',\n",
       " 'spark.databricks.autotune.maintenance.pushUnusedColumnInfo': 'true',\n",
       " 'spark.databricks.sql.functions.aiGen.endpointName': 'databricks-meta-llama-3-3-70b-instruct',\n",
       " 'spark.rpc.message.maxSize': '256',\n",
       " 'spark.hadoop.fs.gs.impl': 'com.databricks.sql.io.LokiFileSystem',\n",
       " 'spark.databricks.workspaceUrl': 'adb-1046699569939209.9.azuredatabricks.net',\n",
       " 'spark.ui.prometheus.enabled': 'true',\n",
       " 'spark.hadoop.spark.sql.parquet.output.committer.class': 'org.apache.spark.sql.parquet.DirectParquetOutputCommitter',\n",
       " 'spark.databricks.autotune.maintenance.client.classname': 'com.databricks.maintenanceautocompute.MACClientImpl',\n",
       " 'spark.databricks.optimizer.doNotUseInvalidAutoStatistics.enabled': 'true',\n",
       " 'spark.databricks.preemption.enabled': 'true',\n",
       " 'spark.databricks.default.table.parquet.compression.codec': 'zstd',\n",
       " 'spark.hadoop.fs.adl.impl.disable.cache': 'true',\n",
       " 'spark.sql.optimizer.datasourceV2JoinPushdown': 'false',\n",
       " 'spark.databricks.autotune.maintenance.client.pushIntervalMinutes': '1',\n",
       " 'spark.databricks.sql.optimizer.statisticsOnLoadSelectDeltaColumnsWithPrecedence': 'true',\n",
       " 'spark.task.reaper.killTimeout': '60s',\n",
       " 'spark.hadoop.hive.server2.enable.doAs': 'false',\n",
       " 'spark.databricks.sql.rowColumnAccess.useEffectivePolicies.enabled': 'true',\n",
       " 'spark.hadoop.fs.s3n.impl': 'com.databricks.sql.io.LokiFileSystem',\n",
       " 'spark.databricks.clusterUsageTags.enableLocalDiskEncryption': 'false',\n",
       " 'spark.databricks.clusterUsageTags.numPerClusterInitScriptsV2': '0',\n",
       " 'spark.databricks.clusterUsageTags.clusterLogDestinationType': '',\n",
       " 'spark.databricks.clusterUsageTags.driverContainerId': '2549285861c7449ba3272670898877fc',\n",
       " 'spark.databricks.clusterUsageTags.sparkEnvVarContainsSingleQuotes': 'false',\n",
       " 'spark.hadoop.fs.fcfs-s3n.impl.disable.cache': 'true',\n",
       " 'spark.databricks.unityCatalog.batchSizeForTableFetchForShowTablesExtended': '100',\n",
       " 'spark.hadoop.fs.azure.skip.metrics': 'true',\n",
       " 'spark.databricks.streaming.foreachBatch.clonedSessionBehavior.enabled': 'false',\n",
       " 'spark.databricks.hmr.nonQueryLogging.bypassRateLimitAllowList': 'AppStatusListener.scala',\n",
       " 'spark.databricks.tahoe.logStore.r2.class': 'com.databricks.tahoe.store.R2LogStore',\n",
       " 'spark.databricks.delta.alterTableSetManaged.skipVacuumableFiles': 'true',\n",
       " 'spark.databricks.delta.stats.localCache.maxNumFiles': '12000',\n",
       " 'spark.databricks.adaptive.dfpExplicitScheduling.broadcastJoinsWithCostModel.enabled': 'false',\n",
       " 'spark.databricks.sql.optimizer.showStatsUsageInExplain.enabled': 'true',\n",
       " 'spark.databricks.credential.scope.fs.wasbs.tokenProviderClassName': 'com.databricks.backend.daemon.driver.credentials.CredentialScopeWASBTokenProvider',\n",
       " 'spark.files.overwrite': 'true',\n",
       " 'spark.databricks.photon.maxMinNestedTypes.enabled': 'false',\n",
       " 'spark.databricks.clusterUsageTags.azureSubscriptionId': 'da2efaf3-ceae-47ea-9e0d-956d0ad738f9',\n",
       " 'spark.databricks.sql.functions.aiFunctions.batch.aiQuery.embedding.request.size': '40',\n",
       " 'spark.databricks.delta.snapshotHint.write.lengthThreshold': '358400',\n",
       " 'spark.databricks.io.parquet.vectorized.nativeFrameReader.taskSamplePercent': '0',\n",
       " 'spark.databricks.delta.logging.async.enabled': 'false',\n",
       " 'spark.sql.sources.commitProtocolClass': 'com.databricks.sql.transaction.directory.DirectoryAtomicCommitProtocol',\n",
       " 'spark.sql.hive.metastore.sharedPrefixes': 'org.mariadb.jdbc,com.mysql.jdbc,org.postgresql,com.microsoft.sqlserver,microsoft.sql.DateTimeOffset,microsoft.sql.Types,com.databricks,com.codahale,com.fasterxml.jackson,shaded.databricks',\n",
       " 'spark.databricks.clusterUsageTags.numPerClusterInitScriptsV2Gcs': '0',\n",
       " 'spark.hadoop.fs.s3a.threads.max': '136',\n",
       " 'spark.databricks.dynamicConf.demoFlag4': '1',\n",
       " 'spark.databricks.clusterUsageTags.clusterNumSshKeys': '0',\n",
       " 'spark.databricks.sql.configMapperClass': 'com.databricks.dbsql.config.SqlConfigMapperBridge',\n",
       " 'spark.sparkr.use.daemon': 'false',\n",
       " 'spark.databricks.delta.dataskipping.directAddFileMaterialization.enabled': 'false',\n",
       " 'spark.databricks.cloudFiles.rocksDB.logLevel': 'ERROR',\n",
       " 'spark.databricks.sql.blockUnsupportedRemoteDataSourcesBeforeGatewayEdgeCheck': 'false',\n",
       " 'spark.databricks.sql.metricView.alterWithFieldMasks.enabled': 'true',\n",
       " 'spark.databricks.prefetchingReader.csv.enabled': 'true',\n",
       " 'spark.streaming.driver.writeAheadLog.allowBatching': 'true',\n",
       " 'spark.databricks.optimizer.optimizeLimit.customPartitionSelection': 'false',\n",
       " 'spark.databricks.adaptive.bloomFilter.explicitScheduling.enableForCommands': 'true',\n",
       " 'spark.databricks.cloudfiles.inferPartitionSchemaInSingleVariantColumn.enabled': 'true',\n",
       " 'spark.databricks.clusterUsageTags.clusterScalingType': 'fixed_size',\n",
       " 'spark.databricks.delta.uniform.iceberg.v3.enabled': 'true',\n",
       " 'spark.databricks.workerNodeTypeId': 'Standard_D4ds_v5',\n",
       " 'spark.databricks.pipelines.useCredentialHelperForDltClientApiToken': 'true',\n",
       " 'spark.hadoop.fs.fcfs-s3.impl.disable.cache': 'true',\n",
       " 'spark.databricks.delta.readclone.postCommit.skipFullUpdatesEnabled': 'MANAGED,MANAGED_SHALLOW_CLONE',\n",
       " 'spark.databricks.clusterUsageTags.effectiveSparkVersion': '17.3.x-photon-scala2.13',\n",
       " 'spark.databricks.delta.skipping.experimentalFilters.validationSelectivity': '0.2',\n",
       " 'spark.databricks.adaptive.skewJoin.handlePushedDownAgg.enabled': 'false',\n",
       " 'spark.databricks.clusterUsageTags.clusterWorkers': '0',\n",
       " 'spark.databricks.delta.typeWidening.allowAutomaticWidening': 'ALWAYS',\n",
       " 'spark.databricks.acl.secureCatalogBatchFilterTables': 'true',\n",
       " 'spark.hadoop.databricks.fs.perfMetrics.enable': 'true',\n",
       " 'spark.databricks.sql.functions.aiFunctions.purposeBuiltFunctions.translate.instruction': '### Instruction\\n\\nTranslate the provided text to %s, and output only the translated text\\nin the target language in this format: <DBSQLAI>translated text</DBSQLAI>.\\n\\nIf the text is already in the target language, output the provided text.\\n\\n### Text\\n\\n%s',\n",
       " 'spark.databricks.pyspark.udf.isolation.factory.idleWorkerMaxPoolSize': '99999',\n",
       " 'spark.databricks.delta.alterTableSetManaged.enabled': 'true',\n",
       " 'spark.databricks.clusterUsageTags.dataPlaneRegion': 'centralindia',\n",
       " 'spark.hadoop.fs.cpfs-s3a.impl': 'com.databricks.sql.acl.fs.CredentialPassthroughFileSystem',\n",
       " 'spark.databricks.sql.functions.aiFunctions.batchSession.enabled': 'true',\n",
       " 'spark.databricks.tahoe.logStore.azure.class': 'com.databricks.tahoe.store.AzureLogStore',\n",
       " 'spark.databricks.delta.optimizeMetadataQuery.shadowExecution.rate': '0.0',\n",
       " 'spark.hadoop.parquet.page.size.check.estimate': 'false',\n",
       " 'spark.databricks.unityCatalog.connectionDfWritesOptionInjection.enabled': 'false',\n",
       " 'spark.hadoop.fs.AbstractFileSystem.gs.impl': 'shaded.databricks.com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS',\n",
       " 'spark.databricks.clusterUsageTags.orgId': '1046699569939209',\n",
       " 'spark.databricks.sql.functions.aiFunctions.embeddingsEndpointName': 'databricks-gte-large-en',\n",
       " 'spark.databricks.clusterUsageTags.numPerClusterInitScriptsV2File': '0',\n",
       " 'spark.executor.memory': '2218m',\n",
       " 'spark.home': '/databricks/spark',\n",
       " 'spark.databricks.unityCatalog.metadataCache.versioned.enabled': 'false',\n",
       " 'spark.databricks.unityCatalog.client.newErrorClasses.enabled': 'false',\n",
       " 'spark.databricks.dataLineage.columnOptimization.enabled': 'false',\n",
       " 'spark.sql.scripting.enabled': 'true',\n",
       " 'spark.databricks.io.native.adlgen2.read.taskSamplePercent': '100',\n",
       " 'spark.databricks.photon.oneRowRelationRowToColumnar.enabled': 'true',\n",
       " 'spark.executor.extraClassPath': '/databricks/hadoop-safety-jars/*:/databricks/spark/dbconf/log4j/executor:/databricks/spark/dbconf/jets3t/:/databricks/spark/dbconf/hadoop:/databricks/hive/conf:/databricks/jars/*',\n",
       " 'spark.hadoop.fs.gs.impl.disable.cache': 'true',\n",
       " 'spark.databricks.sql.metricView.enabled': 'true',\n",
       " 'spark.databricks.sql.functions.aiFunctions.remoteHttpClient.maxConnections': '2048',\n",
       " 'spark.databricks.credential.scope.fs.impl': 'com.databricks.sql.acl.fs.CredentialScopeFileSystem',\n",
       " 'spark.databricks.clusterUsageTags.clusterSpotBidMaxPrice': '-1.0',\n",
       " 'org.apache.spark.sql.util.dynamicSparkConfigUtils.applied': 'true',\n",
       " 'spark.databricks.cloudfetch.requestDownloadUrlsWithHeaders': 'true',\n",
       " 'spark.databricks.photon.mapZipWith.enabled': 'false',\n",
       " 'spark.sql.catalogImplementation': 'hive',\n",
       " 'spark.databricks.singleuser.fuse.scala.enabled': 'false',\n",
       " 'spark.hadoop.fs.cpfs-adl.impl': 'com.databricks.sql.acl.fs.CredentialPassthroughFileSystem',\n",
       " 'spark.databricks.sql.functions.aiFunctions.vectorSearch.maxRetryInterval': '120000',\n",
       " 'spark.databricks.safer.unifiedPath.applyFlag.enabled': 'true',\n",
       " 'spark.hadoop.spark.hadoop.aws.glue.cache.db.ttl-mins': '30',\n",
       " 'spark.databricks.clusterUsageTags.shardName': 'az-centralindia',\n",
       " 'spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.clusterSizeBasedGlobalParallelism.scaleFactor': '512.0',\n",
       " 'spark.databricks.sql.showStatisticsPropertiesInDescribeExtended': 'false',\n",
       " 'spark.databricks.passthrough.s3a.tokenProviderClassName': 'com.databricks.backend.daemon.driver.aws.AwsCredentialContextTokenProvider',\n",
       " 'spark.plugins': 'org.apache.spark.sql.connect.SparkConnectPlugin',\n",
       " 'spark.databricks.clusterUsageTags.isSingleUserCluster': 'true',\n",
       " 'spark.databricks.sql.jdbcDialectIgnoreQueriesWithForbiddenKeywords': 'false',\n",
       " 'spark.databricks.cloudfetch.requesterClassName': 'com.databricks.spark.sql.cloudfetch.DataDaemonCloudPresignedUrlRequester',\n",
       " 'spark.databricks.sql.functions.aiFunctions.modelEndpointTypeParsing.enabled': 'true',\n",
       " 'spark.databricks.clusterUsageTags.sparkEnvVarContainsEscape': 'false',\n",
       " 'spark.databricks.io.native.gcs.write.taskSamplePercent': '100',\n",
       " 'spark.databricks.sqlservice.history.connect.commands.writeStreamOperationStartEnabled': 'true',\n",
       " 'spark.databricks.clusterUsageTags.attribute_tag_dust_suite': '',\n",
       " 'spark.databricks.sql.pythonVectorizedUDF.strictIsolationSyntax.enabled': 'true',\n",
       " 'spark.sparklyr-backend.threads': '1',\n",
       " 'spark.databricks.sql.metricView.snowflake.join.enabled': 'true',\n",
       " 'spark.sql.functions.remoteHttpClient.retryOn400TimeoutError': 'true',\n",
       " 'spark.hadoop.hive.server2.keystore.path': '/databricks/keys/jetty_ssl_driver_keystore.jks',\n",
       " 'spark.hadoop.spark.databricks.io.parquet.verifyChecksumOnWrite.enabled': 'false',\n",
       " 'spark.driver.allowMultipleContexts': 'false',\n",
       " 'spark.databricks.clusterUsageTags.enableSqlAclsOnly': 'false',\n",
       " 'spark.databricks.proxyHadoopTraffic.host': 'storage-proxy.databricks.com',\n",
       " 'spark.databricks.clusterUsageTags.clusterNodeType': 'Standard_D4ds_v5',\n",
       " 'spark.databricks.clusterUsageTags.numPerClusterInitScriptsV2Volumes': '0',\n",
       " 'spark.databricks.sql.metricView.materializations.windowMeasure.enabled': 'true',\n",
       " 'spark.databricks.prefetchingReader.text.enabled': 'false',\n",
       " 'spark.hadoop.spark.hadoop.aws.glue.cache.table.ttl-mins': '30',\n",
       " 'spark.databricks.prefetchingReader.binary.enabled': 'true',\n",
       " 'spark.databricks.autotune.maintenance.enableWorkloadScanMetricsApi': 'true',\n",
       " 'spark.databricks.driverNfs.clusterWidePythonLibsEnabled': 'true',\n",
       " 'spark.databricks.pipelines.moveTableBetweenPipelines.streamingTable.enabled': 'true',\n",
       " 'spark.databricks.cloudFiles.recordEventChanges': 'false',\n",
       " 'spark.hadoop.hive.server2.transport.mode': 'http',\n",
       " 'spark.hadoop.fs.wasb.impl.disable.cache': 'true',\n",
       " 'spark.databricks.passthrough.enabled': 'false',\n",
       " 'spark.databricks.analyzer.resolveRelationsCacheRelationsFromNestedViews': 'false',\n",
       " 'spark.databricks.delta.write.keepNullStructsWithNullType': 'true',\n",
       " 'spark.databricks.clusterUsageTags.containerType': 'LXC',\n",
       " 'spark.databricks.unityCatalog.2hop.rpcAllowlist': 'MetadataAndPermissionsSnapshot,MetadataSnapshot,GetTable,GetSchema,GetCatalog',\n",
       " 'spark.databricks.sql.metricView.viewMatching.enabled': 'true',\n",
       " 'spark.databricks.clusterUsageTags.runtimeEngine': 'PHOTON',\n",
       " 'spark.sql.optimizer.checkDynamicFilePruningExprEligibility': 'false',\n",
       " 'spark.databricks.adaptive.lightReplanning.enabled': 'false',\n",
       " 'spark.sql.allowMultipleContexts': 'false',\n",
       " 'spark.databricks.clusterUsageTags.clusterPythonVersion': '3',\n",
       " 'spark.sql.xml.legacyXMLParser.enabled': 'true',\n",
       " 'spark.databricks.sql.functions.aiForecast.enabled': 'false',\n",
       " 'spark.databricks.cloudfetch.hasRegionSupport': 'true',\n",
       " 'spark.databricks.cloudFiles.sftp.enabled': 'true',\n",
       " 'spark.databricks.sql.metricView.semanticMetadataPropagation.enabled': 'true',\n",
       " 'spark.databricks.unityCatalog.volumes.fuse.server.enabled': 'true',\n",
       " 'spark.hadoop.fs.dbfs.impl.disable.cache': 'true',\n",
       " 'spark.databricks.adaptive.dppExplicitScheduling.broadcastJoinsWithCostModel.enabled': 'false',\n",
       " 'spark.sql.hive.useDatabricksHive122': 'true',\n",
       " 'spark.databricks.delta.write.escapeBackticksWhenDroppingNullType': 'true',\n",
       " 'spark.files.useFetchCache': 'false',\n",
       " 'spark.databricks.clusterUsageTags.enableDfAcls': 'false',\n",
       " 'spark.databricks.sql.functions.aiFunctions.extract.tileMetadata.enabled': 'true',\n",
       " 'spark.databricks.clusterUsageTags.numPerClusterInitScriptsV2S3': '0',\n",
       " 'spark.databricks.dynamicConf.emily.testFlag': 'false',\n",
       " 'spark.databricks.delta.liquid.fixInvalidStateAfterPhaseOut': 'true',\n",
       " 'spark.hadoop.databricks.fs.s3a.dmk.slowPathSampling.probability.double': '0.005',\n",
       " 'spark.hadoop.fs.s3a.impl': 'com.databricks.sql.io.LokiFileSystem',\n",
       " 'spark.databricks.driver.classic.wsfsAsyncFlushEnabled': 'true',\n",
       " 'spark.databricks.connector.mssqlserver.driverVersion': 'current',\n",
       " 'spark.shuffle.memoryFraction': '0.2',\n",
       " 'spark.databricks.sql.pythonUDTF.enabled': 'true',\n",
       " 'spark.sql.functions.remoteHttpClient.retryOnSocketTimeoutException': 'true',\n",
       " 'spark.databricks.delta.liquid.lazyClustering.postOptimizeCompaction.enabled': 'true',\n",
       " 'spark.databricks.unityCatalog.enabled': 'false',\n",
       " 'spark.hadoop.fs.s3a.assumed.role.credentials.provider': 'shaded.databricks.org.apache.hadoop.fs.s3a.DatabricksInstanceProfileCredentialsProvider',\n",
       " 'spark.hadoop.fs.s3a.retry.throttle.interval': '500ms',\n",
       " 'spark.databricks.geo.spatial.rangeShuffle.enabled': 'true',\n",
       " 'spark.databricks.delta.dataskipping.supportDateFormatExprs.enabled': 'false',\n",
       " 'spark.sql.legacy.codingErrorAction': 'true',\n",
       " 'spark.databricks.hive.hmshandler.retry.configs.enabled': 'true',\n",
       " 'spark.databricks.sql.functions.aiFunctions.useDedicatedHttpClient': 'true',\n",
       " 'spark.databricks.delta.delete.metadataOnlyDelete.shadowMode.rate': '0.0',\n",
       " 'spark.databricks.unityCatalog.sftpConnection.disableStrictHostKeyCheck': 'false',\n",
       " 'spark.databricks.delta.uniform.ingress.autoRefresh.enabled': 'true',\n",
       " 'spark.connect.session.connectML.enabled': 'true',\n",
       " 'spark.databricks.delta.skipping.experimentalFilters.validationRate': '0.0',\n",
       " 'spark.databricks.clusterUsageTags.attribute_tag_dust_bazel_path': '',\n",
       " 'spark.databricks.sqlservice.history.multiBatchProfileEnabled': 'true',\n",
       " 'spark.databricks.lakehouseMonitoring.clientClassName': 'com.databricks.datamonitoring.clients.MonitorClientImpl',\n",
       " 'spark.databricks.sql.functions.aiFunctions.createBatchSessionOnExecutor': 'false',\n",
       " 'spark.databricks.adaptive.dpp.explicitSchedulingOfBuildProbeSides': 'true',\n",
       " 'spark.sql.parquet.compression.codec': 'snappy',\n",
       " 'spark.databricks.sql.optimizer.runtimeFiltersMaterializedProbeAsShuffleBoundary': 'true',\n",
       " 'spark.databricks.automl.serviceEnabled': 'true',\n",
       " 'spark.databricks.cluster.profile': 'singleNode',\n",
       " 'spark.databricks.delta.merge.disableSourceMaterializationNotAllowed': 'true',\n",
       " 'spark.databricks.dbrActivityRecorder.frameProfiler.enabled': 'false',\n",
       " 'spark.databricks.sql.excel.enabled': 'true',\n",
       " 'fs.s3a.ifNoneMatch.star.enabled': 'false',\n",
       " 'spark.databricks.abTesting.supportNonDeltaFileFormat': 'false',\n",
       " 'spark.databricks.cloudFiles.cleanSource.enabled': 'true',\n",
       " 'spark.databricks.sql.functions.aiFunctions.remoteHttpClient.timeoutInSeconds': '360',\n",
       " 'spark.sql.sources.default': 'delta',\n",
       " 'spark.databricks.clusterUsageTags.attribute_tag_dust_maintainer': '',\n",
       " 'spark.databricks.sql.optimizer.statisticsOnLoadForStructWithString.enabled': 'true',\n",
       " 'spark.databricks.clusterUsageTags.clusterAvailability': 'ON_DEMAND_AZURE',\n",
       " 'spark.hadoop.mapred.output.committer.class': 'com.databricks.backend.daemon.data.client.DirectOutputCommitter',\n",
       " 'spark.databricks.unityCatalog.glue.federation.enabled': 'true',\n",
       " 'spark.hadoop.databricks.loki.fileStatusCache.enabled': 'true',\n",
       " 'spark.hadoop.fs.s3a.fast.upload.active.blocks': '32',\n",
       " 'spark.databricks.delta.uniform.ingress.enableOnFederation': 'true',\n",
       " 'spark.databricks.optimizer.useStructFieldReferencesForLikelySelectivePred.enabled': 'true',\n",
       " 'spark.databricks.clusterUsageTags.numPerClusterInitScriptsV2Abfss': '0',\n",
       " 'spark.hadoop.spark.sql.sources.outputCommitterClass': 'com.databricks.backend.daemon.data.client.MapReduceDirectOutputCommitter',\n",
       " 'spark.hadoop.fs.cpfs-adl.impl.disable.cache': 'true',\n",
       " 'spark.hadoop.databricks.loki.fileSystemCache.enabled': 'true',\n",
       " 'spark.hadoop.fs.r2.impl': 'com.databricks.sql.io.LokiFileSystem',\n",
       " 'spark.databricks.internalHms.hmshandler.retry.attempts': '3',\n",
       " 'spark.hadoop.parquet.page.write-checksum.enabled': 'true',\n",
       " 'spark.databricks.sql.metricView.materializations.nested.enabled': 'true',\n",
       " 'spark.hadoop.fs.azure.cache.invalidator.type': 'com.databricks.encryption.utils.CacheInvalidatorImpl',\n",
       " 'spark.databricks.sql.optimizer.analyzeSupportForStruct.enabled': 'OFF',\n",
       " 'spark.app.id': 'local-1765880142086',\n",
       " 'com.databricks.safe.ketao.testFlag3': 'false',\n",
       " 'spark.databricks.docingest.maxDocumentPages': '5000',\n",
       " 'spark.databricks.clusterUsageTags.clusterOwnerUserId': '146484896257728',\n",
       " 'spark.hadoop.fs.s3a.fast.upload': 'true',\n",
       " 'spark.databricks.clusterUsageTags.clusterLogDeliveryEnabled': 'false',\n",
       " 'spark.databricks.clusterUsageTags.driverNodeType': 'Standard_D4ds_v5',\n",
       " 'spark.databricks.delta.universalFormatCompatibility.postCommitRefresh.enabled': 'true',\n",
       " 'spark.speculation.quantile': '0.9',\n",
       " 'spark.databricks.cloudProvider': 'Azure',\n",
       " 'spark.databricks.sql.optimizer.collectTableStatisticsOnDataLoad.enabled': 'true',\n",
       " 'spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.threadKeepAliveTimeInSeconds': '600',\n",
       " 'spark.akka.frameSize': '256',\n",
       " 'spark.databricks.sql.functions.aiFunctions.model.parameters.enabled': 'true',\n",
       " 'spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.dynamicPoolSizeEnabled': 'false',\n",
       " 'spark.sql.streaming.optimizer.viewFilterPushDown.enabled': 'true',\n",
       " 'spark.databricks.clusterUsageTags.clusterAllTags': '[{\"key\":\"ResourceClass\",\"value\":\"SingleNode\"},{\"key\":\"Vendor\",\"value\":\"Databricks\"},{\"key\":\"Creator\",\"value\":\"prathmeshpatange01@gmail.com\"},{\"key\":\"ClusterName\",\"value\":\"f1-databricks-cluster-dev\"},{\"key\":\"ClusterId\",\"value\":\"1216-080236-r9lzzt0b\"},{\"key\":\"DatabricksEnvironment\",\"value\":\"workerenv-1046699569939209\"}]',\n",
       " 'spark.databricks.cloudFiles.rocksDB.wal.readerCoordination.enabled': 'false',\n",
       " 'spark.databricks.photon.jniStringToDecimal': 'false',\n",
       " 'spark.sql.hive.metastore.version': '0.13.0'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.getAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ad5d40d-55d7-4db1-a66b-f80ca7b03eec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/Volume/</td><td>Volume/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/Volumes/</td><td>Volumes/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/</td><td>databricks-datasets/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-results/</td><td>databricks-results/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/volume/</td><td>volume/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/volumes/</td><td>volumes/</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/Volume/",
         "Volume/",
         0,
         0
        ],
        [
         "dbfs:/Volumes/",
         "Volumes/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/",
         "databricks-datasets/",
         0,
         0
        ],
        [
         "dbfs:/databricks-results/",
         "databricks-results/",
         0,
         0
        ],
        [
         "dbfs:/volume/",
         "volume/",
         0,
         0
        ],
        [
         "dbfs:/volumes/",
         "volumes/",
         0,
         0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs ls /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4236bcdb-3861-4b6b-bc12-9225b4769cca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>current_date()</th></tr></thead><tbody><tr><td>2025-12-16</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "2025-12-16"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {
             "__autoGeneratedAlias": "true"
            },
            "name": "current_date()",
            "nullable": false,
            "type": "date"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 6
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{\"__autoGeneratedAlias\":\"true\"}",
         "name": "current_date()",
         "type": "\"date\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT current_date()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e022dadd-b2d2-41d6-b838-45599ee09d95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[FileInfo(path='dbfs:/Volume/', name='Volume/', size=0, modificationTime=0),\n",
       " FileInfo(path='dbfs:/Volumes/', name='Volumes/', size=0, modificationTime=0),\n",
       " FileInfo(path='dbfs:/databricks-datasets/', name='databricks-datasets/', size=0, modificationTime=0),\n",
       " FileInfo(path='dbfs:/databricks-results/', name='databricks-results/', size=0, modificationTime=0),\n",
       " FileInfo(path='dbfs:/volume/', name='volume/', size=0, modificationTime=0),\n",
       " FileInfo(path='dbfs:/volumes/', name='volumes/', size=0, modificationTime=0)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbutils.fs.ls(\"/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba75d3b3-9d48-4188-b2cf-ec464fba1497",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div class = \"ansiout\"><b>dbutils.fs</b> provides utilities for working with FileSystems. Most methods in\n",
       "this package can take either a DBFS path (e.g., \"/foo\" or \"dbfs:/foo\"), or\n",
       "another FileSystem URI.\n",
       "\n",
       "For more info about a method, use <b>dbutils.fs.help(\"methodName\")</b>.\n",
       "\n",
       "In notebooks, you can also use the %fs shorthand to access DBFS. The %fs shorthand maps\n",
       "straightforwardly onto dbutils calls. For example, \"%fs head --maxBytes=10000 /file/path\"\n",
       "translates into \"dbutils.fs.head(\"/file/path\", maxBytes = 10000)\".\n",
       "    <h3>fsutils</h3><b>cp(from: String, to: String, recurse: boolean = false): boolean</b> -> Copies a file or directory, possibly across FileSystems<br /><b>head(file: String, maxBytes: int = 65536): String</b> -> Returns up to the first 'maxBytes' bytes of the given file as a String encoded in UTF-8<br /><b>ls(dir: String): Seq</b> -> Lists the contents of a directory<br /><b>mkdirs(dir: String): boolean</b> -> Creates the given directory if it does not exist, also creating any necessary parent directories<br /><b>mv(from: String, to: String, recurse: boolean = false): boolean</b> -> Moves a file or directory, possibly across FileSystems<br /><b>put(file: String, contents: String, overwrite: boolean = false): boolean</b> -> Writes the given String out to a file, encoded in UTF-8<br /><b>rm(dir: String, recurse: boolean = false): boolean</b> -> Removes a file or directory<br /><br /><h3>mount</h3><b>mount(source: String, mountPoint: String, encryptionType: String = \"\", owner: String = null, extraConfigs: Map = Map.empty[String, String]): boolean</b> -> Mounts the given source directory into DBFS at the given mount point<br /><b>mounts: Seq</b> -> Displays information about what is mounted within DBFS<br /><b>refreshMounts: boolean</b> -> Forces all machines in this cluster to refresh their mount cache, ensuring they receive the most recent information<br /><b>unmount(mountPoint: String): boolean</b> -> Deletes a DBFS mount point<br /><b>updateMount(source: String, mountPoint: String, encryptionType: String = \"\", owner: String = null, extraConfigs: Map = Map.empty[String, String]): boolean</b> -> Similar to mount(), but updates an existing mount point (if present) instead of creating a new one<br /><br /></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dbutils.fs.help()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c389c459-a432-4fe3-bbb0-493930e917b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbfs:/databricks-datasets/COVID/CORD-19/\ndbfs:/databricks-datasets/COVID/CSSEGISandData/\ndbfs:/databricks-datasets/COVID/ESRI_hospital_beds/\ndbfs:/databricks-datasets/COVID/IHME/\ndbfs:/databricks-datasets/COVID/USAFacts/\ndbfs:/databricks-datasets/COVID/coronavirusdataset/\ndbfs:/databricks-datasets/COVID/covid-19-data/\ndbfs:/databricks-datasets/COVID/estimated_patient_impact_and_hospital_capacity_by_state/\n"
     ]
    }
   ],
   "source": [
    "for file in dbutils.fs.ls(\"/databricks-datasets/COVID/\"):\n",
    "  if file.name.endswith(\"/\"):\n",
    "    print(file.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d73755a6-d66b-4bf6-8d89-f72f84f485db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div class = \"ansiout\">\n",
       "The notebook module.\n",
       "  <h3></h3><b>exit(value: String): void</b> -> This method lets you exit a notebook with a value<br /><b>run(path: String, timeoutSeconds: int, arguments: Map): String</b> -> This method runs a notebook and returns its exit value<br /><br /></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dbutils.notebook.help()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96eaaa63-f0b8-405f-aba3-438a4989fbcd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Notebook Introduction\n",
    "##Code\n",
    "###Magic Commands\n",
    "- %Python\n",
    "- %SQL\n",
    "- %Scala\n",
    "- %md\n",
    "- %fs\n",
    "- %sh\n",
    "- %run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03e2d1d6-4475-4212-be8d-368bef6751e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UID          PID    PPID  C STIME TTY          TIME CMD\nroot           1       0  0 10:54 ?        00:00:00 /sbin/init\nroot          39       1  0 10:54 ?        00:00:00 /usr/lib/systemd/systemd-journald\nsystemd+     113       1  0 10:54 ?        00:00:00 /usr/lib/systemd/systemd-resolved\nroot         192       1  0 10:54 ?        00:00:00 /usr/sbin/cron -f -P\nmessage+     193       1  0 10:54 ?        00:00:00 @dbus-daemon --system --address=systemd: --nofork --nopidfile --systemd-activation --syslog-only\nroot         195       1  0 10:54 ?        00:00:00 /usr/bin/monit -I\nroot         198       1  0 10:54 ?        00:00:00 /usr/lib/systemd/systemd-logind\nroot         202       1  0 10:54 pts/0    00:00:00 /sbin/agetty -o -p -- \\u --noclear --keep-baud - 115200,38400,9600 vt220\nroot         203       1  0 10:54 pts/1    00:00:00 /sbin/agetty -o -p -- \\u --noclear - vt220\nroot         204       1  0 10:54 pts/2    00:00:00 /sbin/agetty -o -p -- \\u --noclear - vt220\nroot         205       1  0 10:54 pts/3    00:00:00 /sbin/agetty -o -p -- \\u --noclear - vt220\nroot         208       1  0 10:54 pts/4    00:00:00 /sbin/agetty -o -p -- \\u --noclear - vt220\nroot         210       1  0 10:54 ?        00:00:00 /usr/bin/python3 /usr/share/unattended-upgrades/unattended-upgrade-shutdown --wait-for-signal\nsyslog       212       1  0 10:54 ?        00:00:00 /usr/sbin/rsyslogd -n -iNONE\nroot         310       1  0 10:54 ?        00:00:00 /bin/bash /databricks/spark/scripts/fuse/start_wsfs.sh\nroot         317       1  0 10:54 ?        00:00:00 /bin/bash /databricks/spark/scripts/fuse/start_ucfuse.sh\nroot         320     310  0 10:54 ?        00:00:00 /databricks/spark/scripts/fuse/wsfs /Workspace\nroot         340       1  0 10:54 ?        00:00:00 /databricks/spark/scripts/fuse/goofys-dbr -f -o allow_other -o bg --file-mode=0777 --dir-mode=0777 --type-cache-ttl 0 --stat-cache-ttl 1s --http-timeout 120s --uid 65534 --gid 65534 /: /dbfs\nroot         344     317  0 10:54 ?        00:00:00 /databricks/spark/scripts/fuse/goofys-dbr -f -o allow_other --unity_catalog --file-mode=0777 --dir-mode=0777 --type-cache-ttl 0 --stat-cache-ttl 1s --http-timeout 120s --uid 65534 --gid 65534 /: /Volumes\nroot         463       1  0 10:54 ?        00:01:33 java -Dlog4j2.formatMsgNoLookups=true -XX:-UseContainerSupport -XX:+PrintFlagsFinal -XX:+IgnoreUnrecognizedVMOptions --add-modules=jdk.incubator.vector --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED --add-opens=jdk.jfr/jdk.jfr.internal.consumer=ALL-UNNAMED --add-opens=jdk.jfr/jdk.jfr.internal=ALL-UNNAMED --add-opens=java.management/sun.management=ALL-UNNAMED --add-opens=java.base/jdk.internal.loader=ALL-UNNAMED --add-opens=jdk.naming.dns/com.sun.jndi.dns=java.naming --add-opens=java.xml.crypto/com.sun.org.apache.xml.internal.security.utils=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false -Dio.netty.tryReflectionSetAccessible=true -Djava.security.manager=allow --enable-native-access=ALL-UNNAMED -Ddatabricks.completeAllExceptions=true -verbose:gc -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=logs -XX:-OmitStackTraceInFastThrow -Xms1024m -Xmx1024m -Ddatabricks.serviceName=chauffeur-1 -cp /databricks/spark/dbconf/log4j/chauffeur:/databricks/chauffeur-jars/* com.databricks.spark.chauffeur.ChauffeurDaemon\nroot         617     463  0 10:54 ?        00:00:00 bash /databricks/spark/scripts/start_driver.sh /tmp/driver-env.sh\nroot         666     617  0 10:54 ?        00:02:58 /usr/lib/jvm/zulu17-ca-amd64//bin/java -Djava.io.tmpdir=/local_disk0/tmp -XX:-OmitStackTraceInFastThrow -Djava.security.properties=/databricks/spark/dbconf/java/extra.security -XX:-UseContainerSupport -XX:+PrintFlagsFinal -Xlog:gc:stdout:time,uptime,level,tags -Xss4m -Djava.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni -Djavax.xml.datatype.DatatypeFactory=com.sun.org.apache.xerces.internal.jaxp.datatype.DatatypeFactoryImpl -Djavax.xml.parsers.DocumentBuilderFactory=com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderFactoryImpl -Djavax.xml.parsers.SAXParserFactory=com.sun.org.apache.xerces.internal.jaxp.SAXParserFactoryImpl -Djavax.xml.validation.SchemaFactory:http://www.w3.org/2001/XMLSchema=com.sun.org.apache.xerces.internal.jaxp.validation.XMLSchemaFactory -Dorg.xml.sax.driver=com.sun.org.apache.xerces.internal.parsers.SAXParser -Dorg.w3c.dom.DOMImplementationSourceList=com.sun.org.apache.xerces.internal.dom.DOMXSImplementationSourceImpl -Djavax.net.ssl.sessionCacheSize=10000 -Dscala.reflect.runtime.disable.typetag.cache=true -Dcom.google.cloud.spark.bigquery.repackaged.io.netty.tryReflectionSetAccessible=true -Dio.netty.tryReflectionSetAccessible=true -Dlog4j2.formatMsgNoLookups=true -XX:+UseBiasedLocking -XX:+IgnoreUnrecognizedVMOptions --add-modules=jdk.incubator.vector --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED --add-opens=jdk.jfr/jdk.jfr.internal.consumer=ALL-UNNAMED --add-opens=jdk.jfr/jdk.jfr.internal=ALL-UNNAMED --add-opens=java.management/sun.management=ALL-UNNAMED --add-opens=java.base/jdk.internal.loader=ALL-UNNAMED --add-opens=jdk.naming.dns/com.sun.jndi.dns=java.naming --add-opens=java.xml.crypto/com.sun.org.apache.xml.internal.security.utils=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false -Dio.netty.tryReflectionSetAccessible=true -Djava.security.manager=allow --enable-native-access=ALL-UNNAMED -XX:+UseParallelGC -Ddatabricks.serviceName=driver-1 -Xms7850m -Xmx7850m -Dspark.ui.port=40001 -Dspark.executor.extraJavaOptions=-Djava.io.tmpdir=/local_disk0/tmp -XX:ReservedCodeCacheSize=512m -XX:+UseCodeCacheFlushing -XX:PerMethodRecompilationCutoff=-1 -XX:PerBytecodeRecompilationCutoff=-1 -Djava.security.properties=/databricks/spark/dbconf/java/extra.security -XX:-UseContainerSupport -XX:+PrintFlagsFinal -Xlog:gc:stdout:time,uptime,level,tags -Xss4m -Djava.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni -Djavax.xml.datatype.DatatypeFactory=com.sun.org.apache.xerces.internal.jaxp.datatype.DatatypeFactoryImpl -Djavax.xml.parsers.DocumentBuilderFactory=com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderFactoryImpl -Djavax.xml.parsers.SAXParserFactory=com.sun.org.apache.xerces.internal.jaxp.SAXParserFactoryImpl -Djavax.xml.validation.SchemaFactory:http://www.w3.org/2001/XMLSchema=com.sun.org.apache.xerces.internal.jaxp.validation.XMLSchemaFactory -Dorg.xml.sax.driver=com.sun.org.apache.xerces.internal.parsers.SAXParser -Dorg.w3c.dom.DOMImplementationSourceList=com.sun.org.apache.xerces.internal.dom.DOMXSImplementationSourceImpl -Djavax.net.ssl.sessionCacheSize=10000 -Dscala.reflect.runtime.disable.typetag.cache=true -Dcom.google.cloud.spark.bigquery.repackaged.io.netty.tryReflectionSetAccessible=true -Dio.netty.tryReflectionSetAccessible=true -Dlog4j2.formatMsgNoLookups=true -XX:+UseBiasedLocking -XX:+IgnoreUnrecognizedVMOptions --add-modules=jdk.incubator.vector --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED --add-opens=jdk.jfr/jdk.jfr.internal.consumer=ALL-UNNAMED --add-opens=jdk.jfr/jdk.jfr.internal=ALL-UNNAMED --add-opens=java.management/sun.management=ALL-UNNAMED --add-opens=java.base/jdk.internal.loader=ALL-UNNAMED --add-opens=jdk.naming.dns/com.sun.jndi.dns=java.naming --add-opens=java.xml.crypto/com.sun.org.apache.xml.internal.security.utils=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false -Dio.netty.tryReflectionSetAccessible=true -Djava.security.manager=allow --enable-native-access=ALL-UNNAMED -XX:+UseParallelGC -Ddatabricks.serviceName=spark-executor-1 -Dspark.executor.memory=2218m -Dspark.executor.extraClassPath=/databricks/hadoop-safety-jars/*:/databricks/spark/dbconf/log4j/executor:/databricks/spark/dbconf/jets3t/:/databricks/spark/dbconf/hadoop:/databricks/hive/conf:/databricks/jars/* -cp /databricks/hadoop-safety-jars/*:/databricks/spark/dbconf/jets3t/:/databricks/spark/dbconf/log4j/driver:/databricks/hive/conf:/databricks/spark/dbconf/hadoop:/databricks/jars/* com.databricks.backend.daemon.driver.DriverDaemon\nroot         960       1  0 10:55 ?        00:00:00 /databricks/spark/scripts/ttyd/ttyd -p 7681 -d 7 -P 30 -t disableReconnect=true -t disableLeaveAlert=true -f /ttyd/wsfsttyd bash /databricks/spark/scripts/ttyd/set_wsfs_credentials.sh\nroot        1190     666  0 10:55 ?        00:00:09 /local_disk0/.ephemeral_nfs/envs/pythonEnv-2f2cf0d3-bd35-45cb-bfae-eced61941105/bin/python /databricks/python_shell/scripts/db_ipykernel_launcher.py -f /databricks/kernel-connections/94389ad2dec84b754cfbb8b3cf981237f9630ee69208837c620c8f79efb879e9.json\nroot        1305     666  0 10:55 ?        00:00:00 /bin/bash /local_disk0/tmp/_startR.sh12472871192587227853resource.r /local_disk0/tmp/_rServeScript.r5739225133428810745resource.r 1100 None\nroot        1311    1305  0 10:55 ?        00:00:00 /usr/lib/R/bin/exec/R --slave --no-restore -f /local_disk0/tmp/_rServeScript.r5739225133428810745resource.r --args 1100\nroot        1337    1311  0 10:55 ?        00:00:00 /usr/lib/R/bin/exec/R --slave --no-restore -f /local_disk0/tmp/_rServeScript.r5739225133428810745resource.r --args 1100\nroot        2565    1190  0 11:06 ?        00:00:01 /databricks/python-lsp/bin/python /databricks/python-lsp/bin/pylsp --log-file /tmp/python_lsp_logs/python_lsp_server_29eb9087-f07759e29d35a3884013de80_1190.log\nroot        2710    1190  0 11:07 ?        00:00:00 bash\nroot        2711    2710  0 11:07 ?        00:00:00 ps -ef\n"
     ]
    }
   ],
   "source": [
    "%sh\n",
    "ps -ef\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ae2678c-857b-4584-a091-1c89fd2ba279",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 33 bytes.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbutils.fs.put(\n",
    "    \"/tmp/f1_test.txt\",\n",
    "    \"Databricks fundamentals validated\",\n",
    "    overwrite=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6dee93be-f2e2-4715-8c95-6b8784c7dea5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Databricks fundamentals validated'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbutils.fs.head(\"/tmp/f1_test.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e05c888-5742-4946-a56c-fd4eee136988",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Prathmesh'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbutils.widgets.text(\"env\", \"dev\")\n",
    "dbutils.widgets.get(\"env\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70d12eff-ac78-46e7-9068-1c42b0bfd626",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.notebook.exit(\"Databricks fundamentals completed successfully\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7152410734669435,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "01_databricks_fundamentals",
   "widgets": {
    "env": {
     "currentValue": "Prathmesh",
     "nuid": "d46e80cd-0af2-422a-b009-c31b22585bb9",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "dev",
      "label": null,
      "name": "env",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "dev",
      "label": null,
      "name": "env",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}